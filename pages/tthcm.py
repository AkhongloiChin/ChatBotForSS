import streamlit as st
from langchain_ollama.llms import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from retriever import retrieve
from prompt import template

st.set_page_config(
    page_title="T∆∞ t∆∞·ªüng H·ªì Ch√≠ Minh Chatbot",
    page_icon="üìô",
)

# Kh·ªüi t·∫°o m√¥ h√¨nh LLM
model = OllamaLLM(model="llama3")
prompt = ChatPromptTemplate.from_template(template)
chain = prompt | model

# Ti√™u ƒë·ªÅ cho trang
st.title("Chatbot - T∆∞ t∆∞·ªüng H·ªì Ch√≠ Minh")

# T·∫°o √¥ nh·∫≠p li·ªáu cho c√¢u h·ªèi
query = st.text_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:")

# Khi ng∆∞·ªùi d√πng nh·∫≠p c√¢u h·ªèi
if query:
    # Truy v·∫•n v√† l·∫•y k·∫øt qu·∫£ t·ª´ RAG
    results = retrieve(query, 'tthcm.pdf')
    doc = "\n".join(results)  # T·∫°o vƒÉn b·∫£n t·ª´ k·∫øt qu·∫£ truy v·∫•n

    # S·ª≠ d·ª•ng model ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi
    response = chain.invoke({'doc': doc, 'query': query})

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    st.write("C√¢u tr·∫£ l·ªùi t·ª´ chatbot:")
    st.write(response)
