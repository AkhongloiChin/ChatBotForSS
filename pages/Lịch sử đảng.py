import streamlit as st
from langchain_ollama.llms import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from retriever import retrieve
from prompt import template

st.set_page_config(
    page_title="Lá»‹ch sá»­ Äáº£ng Chatbot",
    page_icon="ğŸ“•",
)

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh LLM
model = OllamaLLM(model="llama3")
prompt = ChatPromptTemplate.from_template(template)
chain = prompt | model

# TiÃªu Ä‘á» cho trang
st.title("Chatbot - Lá»‹ch sá»­ Äáº£ng")

# Táº¡o Ã´ nháº­p liá»‡u cho cÃ¢u há»i
query = st.text_input("Nháº­p cÃ¢u há»i cá»§a báº¡n:")

# Khi ngÆ°á»i dÃ¹ng nháº­p cÃ¢u há»i
if query:
    # Truy váº¥n vÃ  láº¥y káº¿t quáº£ tá»« RAG
    results = retrieve(query, 'maclenin.pdf')
    doc = "\n".join(results)  # Táº¡o vÄƒn báº£n tá»« káº¿t quáº£ truy váº¥n

    # Sá»­ dá»¥ng model Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i
    response = chain.invoke({'doc': doc, 'query': query})

    # Hiá»ƒn thá»‹ káº¿t quáº£
    st.write("CÃ¢u tráº£ lá»i tá»« chatbot:")
    st.write(response)
